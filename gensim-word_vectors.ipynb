{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Ejemplo de `word2vec` y `fastText` con `gensim`\n",
    "\n",
    "\n",
    "En la siguiente celda, importamos las librerías necesarias y configuramos los mensajes de los logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import gensim, logging, os\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s : %(levelname)s : %(message)s\", level=logging.INFO\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## word2vec \n",
    "\n",
    "He entrenado un modelo de word2vec con la Wikipedia en español, [tal y como explico aquí](https://github.com/vitojph/kschool-nlp-16/tree/master/misc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "MODEL = \"data/eswiki-300.w2v\"\n",
    "model = gensim.models.Word2Vec.load(MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Probando nuestro modelo\n",
    "\n",
    "El objeto `model` contiene una enorme matriz de números: una tabla, donde cada fila es uno de los términos del vocabulario reconocido y cada columna es una de las características que permiten modelar el significado de dicho término.\n",
    "\n",
    "En nuestro modelo, tal y como está entrenado, tenemos más de 41 millones de términos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(model.corpus_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Cada término del vocabulario está representado como un vector con 300 dimensiones. Podemos acceder al vector de un término concreto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(model.wv[\"azul\"])\n",
    "print(model.wv[\"verde\"])\n",
    "print(model.wv[\"clorofila\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Estos vectores no nos dicen mucho, salvo que contienen números muy pequeños :-/\n",
    "\n",
    "El mismo objeto `model` permite acceder a una serie de funcionalidades ya implementadas que nos van a permitir evaluar formal e informalmente el modelo. Por el momento, nos contentamos con los segundo: vamos a revisar visualmente los significados que nuestro modelo ha aprendido por su cuenta. \n",
    "\n",
    "Podemos calcular la similitud semántica entre dos términos usando el método `similarity`, que nos devuelve un número entre 0 y 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(\"hombre - mujer\", model.wv.similarity(\"hombre\", \"mujer\"))\n",
    "\n",
    "print(\"perro - gato\", model.wv.similarity(\"perro\", \"gato\"))\n",
    "\n",
    "print(\"gato - periódico\", model.wv.similarity(\"gato\", \"periódico\"))\n",
    "\n",
    "print(\"febrero - azul\", model.wv.similarity(\"febrero\", \"azul\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Podemos seleccionar el término que no encaja a partir de una determinada lista de términos usando el método `doesnt_match`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "lista1 = \"madrid barcelona gonzález washington\".split()\n",
    "print(f\"\"\"en la lista '{\" \".join(lista1)}' sobra '{model.wv.doesnt_match(lista1)}'\"\"\")\n",
    "\n",
    "lista2 = \"psoe pp ciu ronaldo\".split()\n",
    "print(f\"\"\"en la lista '{\" \".join(lista2)}' sobra '{model.wv.doesnt_match(lista2)}'\"\"\")\n",
    "\n",
    "lista3 = \"publicaron declararon soy negaron\".split()\n",
    "print(f\"\"\"en la lista '{\" \".join(lista3)}' sobra '{model.wv.doesnt_match(lista3)}'\"\"\")\n",
    "\n",
    "lista4 = \"homero saturno cervantes shakespeare cela\".split()\n",
    "print(f\"\"\"en la lista '{\" \".join(lista4)}' sobra '{model.wv.doesnt_match(lista4)}'\"\"\")\n",
    "\n",
    "lista5 = \"madrid barcelona alpedrete marsella\".split()\n",
    "print(f\"\"\"en la lista '{\" \".join(lista5)}' sobra '{model.wv.doesnt_match(lista5)}'\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Podemos buscar los términos más similares usando el método `most_similar` de nuestro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "terminos = \"azul madrid bmw bici 2019 rock google psoe jay-z xiaomi rajoy brexit saturno césar lazio\".split()\n",
    "\n",
    "for t in terminos:\n",
    "    print(f\"{t} ==> {model.wv.most_similar(t)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Con el mismo método `most_similar` podemos combinar vectores de palabras tratando de jugar con los rasgos semánticos de cada una de ellas para descubrir nuevas relaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(\"mujer que ejerce la autoridad en una alcaldía ==> alcalde + mujer - hombre\")\n",
    "most_similar = model.wv.most_similar(\n",
    "    positive=[\"alcalde\", \"mujer\"], negative=[\"hombre\"], topn=3\n",
    ")\n",
    "for item in most_similar:\n",
    "    print(item)\n",
    "\n",
    "print(\n",
    "    \"mujer especializada en alguna terapia de la medicina ==> doctor + mujer - hombre\"\n",
    ")\n",
    "most_similar = model.wv.most_similar(\n",
    "    positive=[\"doctor\", \"mujer\"], negative=[\"hombre\"], topn=3\n",
    ")\n",
    "for item in most_similar:\n",
    "    print(item)\n",
    "\n",
    "print(\"monarca soberano ==> reina + hombre - mujer\")\n",
    "most_similar = model.wv.most_similar(\n",
    "    positive=[\"reina\", \"hombre\"], negative=[\"mujer\"], topn=3\n",
    ")\n",
    "for item in most_similar:\n",
    "    print(item)\n",
    "\n",
    "print(\"capital de Alemania ==> moscú + alemania - rusia\")\n",
    "most_similar = model.wv.most_similar(\n",
    "    positive=[\"moscú\", \"alemania\"], negative=[\"rusia\"], topn=3\n",
    ")\n",
    "for item in most_similar:\n",
    "    print(item)\n",
    "\n",
    "print(\"presidente de Francia ==> obama + francia - eeuu\")\n",
    "most_similar = model.wv.most_similar(\n",
    "    positive=[\"obama\", \"francia\"], negative=[\"eeuu\"], topn=3\n",
    ")\n",
    "for item in most_similar:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "MODEL = \"~/data/fasttext/cc.en.300.vec\"\n",
    "fasttext = Word2VecKeyedVectors.load_word2vec_format(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(len(fasttext.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(fasttext[\"google\"])\n",
    "print(fasttext[\"Google\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "terms = \"Sun chess boy president hdmi England French Google google keyboard mouse plant\".split()\n",
    "\n",
    "for t in terms:\n",
    "    print(f\"{t} ==> {fasttext.most_similar(t)}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
